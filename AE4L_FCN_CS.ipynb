{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import math\n",
    "import random\n",
    "import gc\n",
    "\n",
    "import numpy as np\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.python.keras import regularizers\n",
    "from tensorflow.python.keras import backend as K\n",
    "from tensorflow.python.keras.backend import set_session\n",
    "from tensorflow.python.keras.models import Model, Sequential, load_model\n",
    "from tensorflow.python.keras.layers import Conv2D, Dense, Input, MaxPooling2D, UpSampling2D, Lambda, Dropout, Concatenate, Add\n",
    "from tensorflow.python.keras.layers import Conv2DTranspose, Activation, Cropping2D, BatchNormalization\n",
    "from tensorflow.python.keras.preprocessing.image import load_img, img_to_array, array_to_img\n",
    "from tensorflow.python.keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "from tensorflow.python.keras.optimizers import Adam, SGD\n",
    "\n",
    "config = tf.ConfigProto(  \n",
    "    gpu_options=tf.GPUOptions(\n",
    "        visible_device_list=\"0\", # specify GPU number\n",
    "        allow_growth=True\n",
    "    )\n",
    ")\n",
    "sess = tf.Session(config=config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NO_CLASS = 20\n",
    "IGNORE_LABEL = np.uint8(19)\n",
    "RESIZE_HEIGHT =512 #image height for network inputting\n",
    "RESIZE_WIDTH = 1024  #image width for network inputting\n",
    "#KNL_INITLZ = 'he_uniform'\n",
    "KNL_INITLZ = 'he_normal'\n",
    "\n",
    "LEARN_RATE = np.float32(1.0e-4)\n",
    "BETA_1 = np.float32(0.99) # for adam\n",
    "MOMENTUM= np.float32(0.9)\n",
    "\n",
    "AL2_VALUE1 = np.float32(1.0e-3) # for encoder\n",
    "AL2_VALUE2 = np.float32(1.0e-3)\n",
    "AL2_VALUE3 = np.float32(1.0e-3)\n",
    "AL2_VALUE4 = np.float32(1.0e-3)\n",
    "\n",
    "FILT_SIZE = (5, 5) # for encoder\n",
    "FILT_NO1 = 96\n",
    "FILT_NO2 = 64\n",
    "FILT_NO3 = 32\n",
    "FILT_NO4 = 16\n",
    "\n",
    "L2_VALUE1 = np.float32(5.0e-4) #for FCN\n",
    "L2_VALUE2 = np.float32(5.0e-4)\n",
    "L2_VALUE3 = np.float32(5.0e-4)\n",
    "\n",
    "BATCH_SIZE = 5\n",
    "EPOCHS1 = 1000\n",
    "EPOCHS2 = 500\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_train_image = \"C:/Users/test/Documents/Cityscapes/Image/Train_Image\"  #path to train image folder\n",
    "path_val_image = \"C:/Users/test/Documents/Cityscapes/Image/Val_Image\"  #path to val image folder\n",
    "\n",
    "path_train_grth = \"C:/Users/test/Documents/Cityscapes/GtImage/Train\"  #path to Train grth folder\n",
    "path_val_grth = \"C:/Users/test/Documents/Cityscapes/GtImage/Val\" #path to Val grth folder\n",
    "\n",
    "path_train_predict_folder = \"C:/Users/test/Documents/Cityscapes/Predict/Train_Predict\" #path to Predict folder\n",
    "path_val_predict_folder = \"C:/Users/test/Documents/Cityscapes/Predict/Val_Predict\" #path to Predict folder\n",
    "\n",
    "#checkpoint_path = \"C:/Users/test/Documents/Cityscapes/Weights/cp-{epoch:04d}-{val_acc:.4f}.hdf5\"  #path to checkpoint(Weights) folder\n",
    "checkpoint_path = \"C:/Users/test/Documents/Cityscapes/Weights/best_weights.hdf5\"  #path to checkpoint(Weights) folder\n",
    "\n",
    "encoder_path = \"C:/Users/test/Documents/Cityscapes/Encoder_Weights/encoder_2022_1_28.hdf5\"  #path to Encoder_Weights folder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palette = np.zeros(256*3, dtype = np.uint8)\n",
    "palette = np.array(palette).reshape(256, 3)\n",
    "palette[0] =  np.array([128, 64,128]) #made by copying labels[ ]\n",
    "palette[1] =  np.array([244, 35,232])\n",
    "palette[2] =  np.array([ 70, 70, 70])\n",
    "palette[3] =  np.array([102,102,156])\n",
    "palette[4] =  np.array([190,153,153])\n",
    "palette[5] =  np.array([153,153,153])\n",
    "palette[6] =  np.array([250,170, 30])\n",
    "palette[7] =  np.array([220,220,  0])\n",
    "palette[8] =  np.array([107,142, 35])\n",
    "palette[9] =  np.array([152,251,152])\n",
    "palette[10] = np.array([ 70,130,180])\n",
    "palette[11] = np.array([220, 20, 60])\n",
    "palette[12] = np.array([255,  0,  0])\n",
    "palette[13] = np.array([  0,  0,142])\n",
    "palette[14] = np.array([  0,  0, 70])\n",
    "palette[15] = np.array([  0, 60,100])\n",
    "palette[16] = np.array([  0, 80,100])\n",
    "palette[17] = np.array([  0,  0,230])\n",
    "palette[18] = np.array([119, 11, 32])\n",
    "palette[19] = np.array([  0,  0,  0])\n",
    "palette = np.array(palette).reshape(-1)\n",
    "palette1 = palette[0: 3*22]\n",
    "palette1 = np.array(palette1).reshape(22, 3)\n",
    "print(\"palette1 shape: \", palette1.shape)\n",
    "#print(\"palette1: \\n\", palette1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_transform(path_image, path_grth):\n",
    "    no_image = 0\n",
    "    image_array_list = []\n",
    "    grth_image_array_list = []\n",
    "    filename = os.listdir(path_image)[0]\n",
    "    image = Image.open(path_image + \"/\" + filename)\n",
    "    width = image.width\n",
    "    tg_size = (RESIZE_WIDTH, RESIZE_HEIGHT)\n",
    "    for filename in os.listdir(path_image):\n",
    "        no_image += 1\n",
    "        image = Image.open(path_image + \"/\" + filename)\n",
    "        image = image.convert(\"RGB\")\n",
    "        if width != RESIZE_WIDTH:\n",
    "            image = image.resize(tg_size, PIL.Image.ANTIALIAS)    \n",
    "        image_array = np.asarray(image, dtype=np.uint8)\n",
    "        image_array_list.append(image_array)\n",
    "        length = len(filename)\n",
    "        length1 = length - 16\n",
    "        string = filename[0:length1]\n",
    "        filename1 = string + \"_gtFine_labelIds.png\"\n",
    "        try:\n",
    "            grth_image = Image.open(path_grth + \"/\" + filename1)\n",
    "        except:\n",
    "            print(filename1 + \"does nor exist\")\n",
    "            break\n",
    "        if width != RESIZE_WIDTH:\n",
    "            grth_image = grth_image.resize(tg_size, PIL.Image.NEAREST)    \n",
    "        grth_image_array = np.asarray(grth_image, dtype=np.uint8)\n",
    "        grth_image_array_list.append(grth_image_array)\n",
    "            \n",
    "#        if no_image == 20:  #break for debug mode\n",
    "#            break\n",
    "           \n",
    "    return no_image, image_array_list, grth_image_array_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_no_image, train_image_array_list, train_grth_image_array_list = data_transform(path_train_image, path_train_grth)\n",
    "print(\"trai_no_image = \", train_no_image)\n",
    "print(\"train data have been prepared successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_no_image, val_image_array_list, val_grth_image_array_list = data_transform(path_val_image, path_val_grth)\n",
    "print(\"val_no_image = \", val_no_image)\n",
    "print(\"val data have been prepared successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"display processed train data for checking\")\n",
    "\n",
    "from IPython.display import display_png\n",
    "\n",
    "no = 0\n",
    "for i in range(2):\n",
    "    print(\"processed no = \", no)\n",
    "    train_image = Image.fromarray(np.uint8(train_image_array_list[i]), mode=\"RGB\")\n",
    "    display_png(train_image)\n",
    "    grth_image = Image.fromarray(np.uint8(train_grth_image_array_list[i]), mode=\"P\")\n",
    "    grth_image.putpalette(palette)\n",
    "    display_png(grth_image)\n",
    "    no += 1\n",
    "    \n",
    "print(\"final processed no = \", no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"display processed val data for checking\")\n",
    "\n",
    "from IPython.display import display_png\n",
    "\n",
    "no = 0\n",
    "for i in range(2):\n",
    "    print(\"processed no = \", no)\n",
    "    val_image = Image.fromarray(np.uint8(val_image_array_list[i]), mode=\"RGB\")\n",
    "    display_png(val_image)\n",
    "    grth_image = Image.fromarray(np.uint8(val_grth_image_array_list[i]), mode=\"P\")\n",
    "    grth_image.putpalette(palette)\n",
    "    display_png(grth_image)\n",
    "    no += 1\n",
    "    \n",
    "print(\"final processed no = \", no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_data = np.array(train_image_array_list, dtype=np.float32)\n",
    "train_input_data = train_input_data / np.float32(255.0)\n",
    "train_input_data = train_input_data.reshape((-1, RESIZE_HEIGHT, RESIZE_WIDTH, 3))\n",
    "\n",
    "train_grth_data = np.array(train_grth_image_array_list)\n",
    "train_grth_data = train_grth_data.reshape((-1, RESIZE_HEIGHT, RESIZE_WIDTH, 1))\n",
    "\n",
    "print(\"train_input_data.shape = \", train_input_data.shape)\n",
    "print(\"train_grth__data.shape = \", train_grth_data.shape)\n",
    "print(\"train_input_data and train_grth_data have been transformed successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_input_data = np.array(val_image_array_list, dtype=np.float32)\n",
    "val_input_data = val_input_data / np.float32(255.0)\n",
    "val_input_data = val_input_data.reshape((-1, RESIZE_HEIGHT, RESIZE_WIDTH, 3))\n",
    "\n",
    "val_grth_data = np.array(val_grth_image_array_list)\n",
    "val_grth_data = val_grth_data.reshape((-1, RESIZE_HEIGHT, RESIZE_WIDTH, 1))\n",
    "\n",
    "print(\"val_input_data.shape = \", val_input_data.shape)\n",
    "print(\"val_grth__data.shape = \", val_grth_data.shape)\n",
    "print(\"val_input_data and val_grth_data have been transformed successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_size(tps_tensor, tgt_tensor):\n",
    "    h_tps = tps_tensor.shape[1]\n",
    "    w_tps = tps_tensor.shape[2]\n",
    "    h_tgt = tgt_tensor.shape[1]\n",
    "    w_tgt = tgt_tensor.shape[2]\n",
    "    h_crop = (h_tps - h_tgt) // 2\n",
    "    w_crop = (w_tps - w_tgt) // 2\n",
    "    \n",
    "    h = h_tgt + h_crop + h_crop\n",
    "    assert h == h_tps, \"h == h_tps does not hold\"\n",
    "\n",
    "    w = w_tgt + w_crop + w_crop\n",
    "    assert w == w_tps, \"w == w_tps does not hold\"\n",
    "\n",
    "    return h_crop, w_crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = Input(shape=(RESIZE_HEIGHT, RESIZE_WIDTH, 3))\n",
    "\n",
    "# AIFE4_CS2 Encoder\n",
    "# Filter 1\n",
    "e = Conv2D(FILT_NO1, FILT_SIZE, 1, activation='relu', padding='same', kernel_initializer=KNL_INITLZ,\n",
    "        kernel_regularizer=regularizers.l2(AL2_VALUE1))(input)\n",
    "e = BatchNormalization()(e)\n",
    "    \n",
    "# Filter 2\n",
    "e = Conv2D(FILT_NO2, (3, 3), 1, activation='relu', padding='same', kernel_initializer=KNL_INITLZ,\n",
    "        kernel_regularizer=regularizers.l2(AL2_VALUE2))(e)\n",
    "e = BatchNormalization()(e)\n",
    "\n",
    "# Filter 3\n",
    "e = Conv2D(FILT_NO3, (3, 3), 1, activation='relu', padding='same', kernel_initializer=KNL_INITLZ,\n",
    "        kernel_regularizer=regularizers.l2(AL2_VALUE3))(e)\n",
    "e = BatchNormalization()(e)\n",
    "\n",
    "# Filter 4, output is bottleneck\n",
    "e = Conv2D(FILT_NO4, (3, 3), 1, activation='relu', padding='same', kernel_initializer=KNL_INITLZ,\n",
    "        kernel_regularizer=regularizers.l2(AL2_VALUE4))(e)\n",
    "bottleneck = BatchNormalization()(e)\n",
    "\n",
    "encoder = Model(inputs=[input], outputs=[bottleneck])\n",
    "encoder.load_weights(encoder_path)\n",
    "\n",
    "#FCN8s BLOCK\n",
    "# Block 1\n",
    "c = Conv2D(64, (3, 3), 1, activation='relu', padding='same', kernel_initializer=KNL_INITLZ,\n",
    "        kernel_regularizer=regularizers.l2(L2_VALUE1))(bottleneck)\n",
    "c = BatchNormalization()(c)\n",
    "c = Conv2D(64, (3, 3), 1, activation='relu', padding='same', kernel_initializer=KNL_INITLZ,\n",
    "        kernel_regularizer=regularizers.l2(L2_VALUE1))(c)\n",
    "pool1 = MaxPooling2D((2, 2), padding='same')(c)\n",
    "    \n",
    "# Block 2\n",
    "c = Conv2D(128, (3, 3), 1, activation='relu', padding='same', kernel_initializer=KNL_INITLZ,\n",
    "        kernel_regularizer=regularizers.l2(L2_VALUE1))(pool1)\n",
    "c = Conv2D(128, (3, 3), 1, activation='relu', padding='same', kernel_initializer=KNL_INITLZ,\n",
    "        kernel_regularizer=regularizers.l2(L2_VALUE1))(c)\n",
    "pool2 = MaxPooling2D((2, 2), padding='same')(c)\n",
    "\n",
    "# Block 3\n",
    "c = Conv2D(256, (3, 3), 1, activation='relu', padding='same', kernel_initializer=KNL_INITLZ,\n",
    "        kernel_regularizer=regularizers.l2(L2_VALUE1))(pool2)\n",
    "c = Conv2D(256, (3, 3), 1, activation='relu', padding='same', kernel_initializer=KNL_INITLZ,\n",
    "        kernel_regularizer=regularizers.l2(L2_VALUE1))(c)\n",
    "c = Conv2D(256, (3, 3), 1, activation='relu', padding='same', kernel_initializer=KNL_INITLZ,\n",
    "        kernel_regularizer=regularizers.l2(L2_VALUE1))(c)\n",
    "pool3 = MaxPooling2D((2, 2), padding='same')(c)\n",
    "\n",
    "# Block 4\n",
    "c = Conv2D(512, (3, 3), 1, activation='relu', padding='same', kernel_initializer=KNL_INITLZ,\n",
    "        kernel_regularizer=regularizers.l2(L2_VALUE1))(pool3)\n",
    "c = Conv2D(512, (3, 3), 1, activation='relu', padding='same', kernel_initializer=KNL_INITLZ,\n",
    "        kernel_regularizer=regularizers.l2(L2_VALUE1))(c)\n",
    "c = Conv2D(512, (3, 3), 1, activation='relu', padding='same', kernel_initializer=KNL_INITLZ,\n",
    "        kernel_regularizer=regularizers.l2(L2_VALUE1))(c)\n",
    "pool4 = MaxPooling2D((2, 2), padding='same')(c)\n",
    "\n",
    "# Block 5\n",
    "c = Conv2D(512, (3, 3), 1, activation='relu', padding='same', kernel_initializer=KNL_INITLZ,\n",
    "        kernel_regularizer=regularizers.l2(L2_VALUE1))(pool4)\n",
    "c = Conv2D(512, (3, 3), 1, activation='relu', padding='same', kernel_initializer=KNL_INITLZ,\n",
    "        kernel_regularizer=regularizers.l2(L2_VALUE1))(c)\n",
    "c = Conv2D(512, (3, 3), 1, activation='relu', padding='same', kernel_initializer=KNL_INITLZ,\n",
    "        kernel_regularizer=regularizers.l2(L2_VALUE1))(c)\n",
    "pool5 = MaxPooling2D((2, 2), padding='same')(c)\n",
    "\n",
    "# fully conv\n",
    "f = Conv2D(4096, (7, 7), 1, activation='relu' , padding='same', kernel_initializer=KNL_INITLZ,\n",
    "        kernel_regularizer=regularizers.l2(L2_VALUE1))(pool5)\n",
    "d = Dropout(0.5)(f)\n",
    "f = Conv2D(4096, (1, 1), 1, activation='relu', kernel_initializer=KNL_INITLZ,\n",
    "        kernel_regularizer=regularizers.l2(L2_VALUE2))(d)\n",
    "d = Dropout(0.5)(f)\n",
    "score_fr = Conv2D(NO_CLASS, (1, 1), 1, kernel_initializer=KNL_INITLZ,\n",
    "        kernel_regularizer=regularizers.l2(L2_VALUE2))(d)\n",
    "\n",
    "#scorinag pool4\n",
    "score_pool4 = Conv2D(NO_CLASS, (1, 1) , 1, kernel_initializer=KNL_INITLZ,\n",
    "        kernel_regularizer=regularizers.l2(L2_VALUE2))(pool4)\n",
    "score_pool4 = BatchNormalization()(score_pool4)\n",
    "\n",
    "# 2 times upsamping and cropping score_fr layer\n",
    "upscore2 = Conv2DTranspose(NO_CLASS, kernel_size=(4, 4), strides=(2, 2), padding='valid', use_bias=False,\n",
    "        kernel_initializer=KNL_INITLZ, kernel_regularizer=regularizers.l2(L2_VALUE3))(score_fr)\n",
    "h_crop, w_crop = crop_size(upscore2, score_pool4)\n",
    "print(\"h_crop = \", h_crop)\n",
    "print(\"w_crop = \", w_crop)\n",
    "h = np.int32(h_crop)\n",
    "w = np.int32(w_crop)\n",
    "upscore2c = Cropping2D(cropping=((h, h), (w, w)))(upscore2)\n",
    "#upscore2c = Cropping2D(cropping=((1, 1), (1, 1)))(upscore2)\n",
    "upscore2c = BatchNormalization()(upscore2c)\n",
    "print(\"upscore2.shape = \", upscore2.shape)\n",
    "print(\"upscore2c.shape = \", upscore2c.shape)\n",
    "\n",
    "# Add [score_pool4, upscore2]\n",
    "fuse_pool4 = Add()([score_pool4, upscore2c])\n",
    "\n",
    "#scorining pool3\n",
    "score_pool3 = Conv2D(NO_CLASS, (1, 1), 1, kernel_initializer=KNL_INITLZ,\n",
    "        kernel_regularizer=regularizers.l2(L2_VALUE2))(pool3)\n",
    "score_pool3 = BatchNormalization()(score_pool3)\n",
    "\n",
    "# 2 times upsampling and cropping fuse_pool4\n",
    "upscore_pool4 = Conv2DTranspose(NO_CLASS, kernel_size=(4, 4), strides=(2, 2), padding='valid', use_bias=False,\n",
    "        kernel_initializer=KNL_INITLZ, kernel_regularizer=regularizers.l2(L2_VALUE3))(fuse_pool4)\n",
    "h_crop, w_crop = crop_size(upscore_pool4, score_pool3)\n",
    "h = np.int32(h_crop)\n",
    "w = np.int32(w_crop)\n",
    "upscore_pool4c = Cropping2D(cropping=((h, h), (w, w)))(upscore_pool4)\n",
    "#upscore_pool4c = Cropping2D(cropping=((, 1), (1, 1)))(upscore_pool4)\n",
    "upscore_pool4c = BatchNormalization()(upscore_pool4c)\n",
    "print(\"upscore_pool4.shape = \", upscore_pool4.shape)\n",
    "print(\"upscore_pool4c.shape = \", upscore_pool4c.shape)\n",
    "\n",
    "# Add [score_pool3, upscore_pool4]\n",
    "fuse_pool3 = Add()([score_pool3, upscore_pool4c])\n",
    "\n",
    "# 8 times upsampling fuse_pool3 and cropping upscore8 into the input size\n",
    "upscore8 = Conv2DTranspose(NO_CLASS, kernel_size=(16, 16),  strides=(8, 8), padding='valid', use_bias=False,\n",
    "        kernel_initializer=KNL_INITLZ, kernel_regularizer=regularizers.l2(L2_VALUE3))(fuse_pool3)\n",
    "h_crop, w_crop = crop_size(upscore8, input)\n",
    "h = np.int32(h_crop)\n",
    "w = np.int32(w_crop)\n",
    "upscore8c = Cropping2D(cropping=((h, h), (w, w)))(upscore8)\n",
    "#upscore8c = Cropping2D(cropping=((4, 4), (4, 4)))(upscore8)\n",
    "print(\"upscore8.shape = \", upscore8.shape)\n",
    "print(\"upscore8c.shape = \", upscore8c.shape)\n",
    "\n",
    "score= (Activation('softmax'))(upscore8c)\n",
    "print(\"score.shape = \", score.shape)\n",
    "\n",
    "model = Model(inputs=[input], outputs=[score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = SGD(lr=LEARN_RATE, momentum=MOMENTUM, nesterov=True)\n",
    "#adam = Adam(lr=LEARN_RATE, beta_1=BETA_1)\n",
    "\n",
    "model.compile(\n",
    "#    optimizer = adam,\n",
    "    optimizer = sgd,\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics = ['accuracy']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tsb=TensorBoard(log_dir='.logs')\n",
    "c_weight = [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0]\n",
    "print(\"c_weight = \", c_weight)\n",
    "modelcp = ModelCheckpoint(filepath = checkpoint_path,\n",
    "                                  monitor='val_acc',\n",
    "                                  verbose=1,\n",
    "                                  save_best_only=True,\n",
    "                                  save_weights_only=True,\n",
    "                                  mode='max',\n",
    "                                  period=1)\n",
    "\n",
    "history1 = model.fit(\n",
    "    train_input_data, \n",
    "    train_grth_data, \n",
    "    initial_epoch = 0,\n",
    "    epochs = EPOCHS1,     \n",
    "    batch_size = BATCH_SIZE,\n",
    "    shuffle = True,   \n",
    "    class_weight = c_weight,    \n",
    "    callbacks = [tsb, modelcp],\n",
    "    validation_data=(val_input_data, val_grth_data)\n",
    "    )\n",
    "np.save(\"history1.npy\", history1.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history2 = model.fit(\n",
    "    train_input_data, \n",
    "    train_grth_data, \n",
    "    initial_epoch = EPOCHS1,\n",
    "    epochs = EPOCHS1+EPOCHS2,    \n",
    "    batch_size = BATCH_SIZE, \n",
    "    shuffle = True,   \n",
    "    class_weight = c_weight,\n",
    "    callbacks = [tsb, modelcp],\n",
    "    validation_data=(val_input_data, val_grth_data)\n",
    "    )\n",
    "np.save(\"history2.npy\", history2.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history3 = model.fit(\n",
    "    train_input_data, \n",
    "    train_grth_data, \n",
    "    initial_epoch = EPOCHS1+EPOCHS2,\n",
    "    epochs = EPOCHS1+2*EPOCHS2,     \n",
    "    batch_size = BATCH_SIZE, \n",
    "    shuffle = True,   \n",
    "    class_weight = c_weight,    \n",
    "    callbacks = [tsb, modelcp],\n",
    "    validation_data=(val_input_data, val_grth_data)\n",
    "    )\n",
    "np.save(\"history3.npy\", history3.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history4 = model.fit(\n",
    "    train_input_data, \n",
    "    train_grth_data, \n",
    "    initial_epoch = EPOCHS1+2*EPOCHS2,\n",
    "    epochs = EPOCHS1+3*EPOCHS2,    \n",
    "    batch_size = BATCH_SIZE, \n",
    "    shuffle = True,   \n",
    "    class_weight = c_weight,    \n",
    "    callbacks = [tsb, modelcp],\n",
    "    validation_data=(val_input_data, val_grth_data)\n",
    "    )\n",
    "np.save(\"history4.npy\", history4.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history5 = model.fit(\n",
    "    train_input_data, \n",
    "    train_grth_data, \n",
    "    initial_epoch = EPOCHS1+3*EPOCHS2,\n",
    "    epochs = EPOCHS1+4*EPOCHS2,    \n",
    "    batch_size = BATCH_SIZE, \n",
    "    shuffle = True,   \n",
    "    class_weight = c_weight,    \n",
    "    callbacks = [tsb, modelcp],\n",
    "    validation_data=(val_input_data, val_grth_data)\n",
    "    )\n",
    "np.save(\"history5.npy\", history5.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history6 = model.fit(\n",
    "    train_input_data, \n",
    "    train_grth_data, \n",
    "    initial_epoch = EPOCHS1+4*EPOCHS2,\n",
    "    epochs = EPOCHS1+5*EPOCHS2,    \n",
    "    batch_size = BATCH_SIZE, \n",
    "    shuffle = True,   \n",
    "    class_weight = c_weight,    \n",
    "    callbacks = [tsb, modelcp],\n",
    "    validation_data=(val_input_data, val_grth_data)\n",
    "    )\n",
    "np.save(\"history6.npy\", history6.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history7 = model.fit(\n",
    "    train_input_data, \n",
    "    train_grth_data, \n",
    "    initial_epoch = EPOCHS1+5*EPOCHS2,\n",
    "    epochs = EPOCHS1+6*EPOCHS2,     \n",
    "    batch_size = BATCH_SIZE, \n",
    "    shuffle = True,  \n",
    "    class_weight = c_weight,    \n",
    "    callbacks = [tsb, modelcp],\n",
    "    validation_data=(val_input_data, val_grth_data)\n",
    "    )\n",
    "np.save(\"history7.npy\", history7.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(checkpoint_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display_png\n",
    "\n",
    "def display_image(input_image, predict_image):\n",
    "    display_png(input_image)\n",
    "    display_png(predict_image) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train image predict and save predict image\n",
    "\n",
    "grth_file_list = os.listdir(path_train_grth)\n",
    "tno_data = len(train_input_data)\n",
    "i = 0\n",
    "for i in range(10):    \n",
    "    input = train_input_data[i]\n",
    "    input_bt = np.expand_dims(input, axis=0)\n",
    "    \n",
    "    predict_bt = model.predict_on_batch(input_bt)\n",
    "\n",
    "    predict = np.squeeze(predict_bt, 0)\n",
    "    predict = np.argmax(predict, axis=2)\n",
    "    train_predict_image = Image.fromarray(np.uint8(predict), mode=\"P\")\n",
    "    train_predict_image.putpalette(palette)\n",
    "    filename = grth_file_list[i]\n",
    "    length = len(filename)\n",
    "    length1 = length - 19\n",
    "    string = filename[0:length1]\n",
    "    filename1 = string + \"TrainPredict.png\"\n",
    "    train_predict_image_r = train_predict_image.resize((2048,1024), PIL.Image.ANTIALIAS)    \n",
    "    train_predict_image_r.save(path_train_predict_folder + \"/\" + filename1)\n",
    "\n",
    "    train_grth_image_array = train_grth_image_array_list[i]\n",
    "    train_grth_image = Image.fromarray(np.uint8(train_grth_image_array), mode=\"P\")\n",
    "    train_grth_image.putpalette(palette)\n",
    "\n",
    "    display_png(train_grth_image)\n",
    "    display_png(train_predict_image)\n",
    "    print(\"i = \", i)\n",
    "\n",
    "print(\"processing has finished successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# val image predict and save predict image\n",
    "\n",
    "grth_file_list = os.listdir(path_val_grth)\n",
    "tno_data = len(val_input_data)\n",
    "i = 0\n",
    "for i in range(tno_data):    \n",
    "    input = val_input_data[i]\n",
    "    input_bt = np.expand_dims(input, axis=0)\n",
    "    \n",
    "    predict_bt = model.predict_on_batch(input_bt)\n",
    "\n",
    "    predict = np.squeeze(predict_bt, 0)\n",
    "    predict = np.argmax(predict, axis=2)\n",
    "    val_predict_image = Image.fromarray(np.uint8(predict), mode=\"P\")\n",
    "    val_predict_image.putpalette(palette)\n",
    "    filename = grth_file_list[i]\n",
    "    length = len(filename)\n",
    "    length1 = length - 19\n",
    "    string = filename[0:length1]\n",
    "    filename1 = string + \"ValPredict.png\"\n",
    "    val_predict_image_r = val_predict_image.resize((2048,1024), PIL.Image.ANTIALIAS)    \n",
    "    val_predict_image_r.save(path_val_predict_folder + \"/\" + filename1)\n",
    "\n",
    "    val_grth_image_array = val_grth_image_array_list[i]\n",
    "    val_grth_image = Image.fromarray(np.uint8(val_grth_image_array), mode=\"P\")\n",
    "    val_grth_image.putpalette(palette)\n",
    "\n",
    "    if i%250 == 0:\n",
    "        display_png(val_grth_image)\n",
    "        display_png(val_predict_image)\n",
    "        print(\"i = \", i)\n",
    "\n",
    "print(\"i = \", i)\n",
    "print(\"processing has finished successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss, train_acc = model.evaluate(train_input_data, train_grth_data)\n",
    "print(\"Restored model, train_loss: {:.4f}\".format(train_loss))\n",
    "print(\"Restored model, train_acc: {:.4f}\".format(train_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss, val_acc = model.evaluate(val_input_data, val_grth_data)\n",
    "print(\"Restored model, val_loss: {:.4f}\".format(val_loss))\n",
    "print(\"Restored model, val_acc: {:.4f}\".format(val_acc))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
