{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import math\n",
    "import random\n",
    "import gc\n",
    "\n",
    "import numpy as np\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.python.keras import regularizers\n",
    "from tensorflow.python.keras import backend as K\n",
    "from tensorflow.python.keras.backend import set_session\n",
    "from tensorflow.python.keras.models import Model, Sequential, load_model\n",
    "from tensorflow.python.keras.layers import Conv2D, Dense, Input, MaxPooling2D, UpSampling2D, Lambda, Dropout, Concatenate, Add\n",
    "from tensorflow.python.keras.layers import Conv2DTranspose, Activation, Cropping2D, BatchNormalization\n",
    "from tensorflow.python.keras.preprocessing.image import load_img, img_to_array, array_to_img\n",
    "from tensorflow.python.keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "from tensorflow.python.keras.optimizers import Adam, SGD\n",
    "\n",
    "config = tf.ConfigProto(  \n",
    "    gpu_options=tf.GPUOptions(\n",
    "        visible_device_list=\"0\", # specify GPU number\n",
    "        allow_growth=True\n",
    "    )\n",
    ")\n",
    "sess = tf.Session(config=config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NO_CLASS = 20\n",
    "IGNORE_LABEL = np.uint8(19)\n",
    "RESIZE_HEIGHT =512 #image height for network inputting\n",
    "RESIZE_WIDTH = 1024  #image width for network inputting\n",
    "#KNL_INITLZ = 'he_uniform'\n",
    "KNL_INITLZ = 'he_normal'\n",
    "\n",
    "#CRP_TYPE = 0 # pixel value = 0\n",
    "CRP_TYPE = 1 # pixel value = salt_and_pepper noise\n",
    "PRB_PXLCRP = 0.5 #Coruption Type: bengio, probability of each pixel corruption\n",
    "\n",
    "LEARN_RATE = np.float32(1.0e-4)\n",
    "BETA_1 = np.float32(0.99) # for adam\n",
    "MOMENTUM= np.float32(0.9)\n",
    "\n",
    "L2_VALUE1 = np.float32(1.0e-3)\n",
    "L2_VALUE2 = np.float32(1.0e-3)\n",
    "L2_VALUE3 = np.float32(1.0e-3)\n",
    "L2_VALUE4 = np.float32(1.0e-3)\n",
    "\n",
    "FILT_SIZE = (3, 3)\n",
    "FILT_NO1 = 96\n",
    "FILT_NO2 = 64\n",
    "FILT_NO3 = 32\n",
    "FILT_NO4 = 16\n",
    "\n",
    "BATCH_SIZE = 4\n",
    "EPOCHS1 = 1000\n",
    "EPOCHS2 = 500\n",
    "\n",
    "#PERIOD = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_train_image = \"C:/Users/test/Documents/Cityscapes/Image/Train_Image\"  #path to train image folder\n",
    "path_val_image = \"C:/Users/test/Documents/Cityscapes/Image/Val_Image\"  #path to val image folder\n",
    "\n",
    "checkpoint_path = \"C:/Users/test/Documents/Cityscapes/Weights/best_weights.hdf5\"  #path to checkpoint(Weights) folder\n",
    "\n",
    "encoder_path = \"C:/Users/test/Documents/Cityscapes/Encoder_Weights/encoder.hdf5\"  #path to Encoder_Weights folder\n",
    "\n",
    "path_History = \"C:/Users/test/Documents/Cityscapes/History\"  #path to History folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_transform1(path_image):\n",
    "    \n",
    "    no_image = 0\n",
    "    input_image_array_list = []\n",
    "    filename = os.listdir(path_image)[0]\n",
    "    image = Image.open(path_image + \"/\" + filename)\n",
    "    width = image.width\n",
    "    tg_size = (RESIZE_WIDTH, RESIZE_HEIGHT)\n",
    "    for filename in os.listdir(path_image):\n",
    "        image = Image.open(path_image + \"/\" + filename)\n",
    "        image = image.convert(\"RGB\")\n",
    "        if width != RESIZE_WIDTH:\n",
    "            image = image.resize(tg_size, PIL.Image.ANTIALIAS)\n",
    "        image_array = np.array(image, dtype=np.uint8)\n",
    "        \n",
    "#        no_ptbpxl = 0\n",
    "        if CRP_TYPE == 0:\n",
    "            for y in range(RESIZE_HEIGHT):\n",
    "                for x in range(RESIZE_WIDTH):\n",
    "                    randu = random.uniform(0.0, 1.0)\n",
    "                    if randu <= PRB_PXLCRP:\n",
    "#                        no_ptbpxl += 1\n",
    "                        image_array.itemset((y, x, 0), 0)\n",
    "                        image_array.itemset((y, x, 1), 0)\n",
    "                        image_array.itemset((y, x, 2), 0)\n",
    "        if CRP_TYPE == 1:\n",
    "            for y in range(RESIZE_HEIGHT):\n",
    "                for x in range(RESIZE_WIDTH):\n",
    "                    randu1 = random.uniform(0.0, 1.0)\n",
    "                    if randu1 <= PRB_PXLCRP:\n",
    "#                        no_ptbpxl += 1\n",
    "                        randu2 = random.uniform(0.0, 1.0)\n",
    "                        if randu2 <= 0.5:\n",
    "                            image_array.itemset((y, x, 0), 0)\n",
    "                            image_array.itemset((y, x, 1), 0)\n",
    "                            image_array.itemset((y, x, 2), 0)\n",
    "                        else:\n",
    "                            image_array.itemset((y, x, 0), 255)\n",
    "                            image_array.itemset((y, x, 1), 255)\n",
    "                            image_array.itemset((y, x, 2), 255)\n",
    "                                \n",
    "        input_image_array_list.append(image_array)\n",
    "#        print(\"no_ptbpxl = \", no_ptbpxl)\n",
    "        if no_image%100 == 0:\n",
    "            print(\"no_image = \", no_image)\n",
    "        no_image += 1\n",
    "#        if no_image == 20:  #break for debug mode\n",
    "#            break\n",
    "            \n",
    "    return no_image, input_image_array_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crpt_no_image, crpt_image_array_list = data_transform1(path_train_image)\n",
    "print(\"crpt_no_image = \", crpt_no_image)\n",
    "print(\"crpt data have been prepared successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_transform2(path_image):\n",
    "    no_image = 0\n",
    "    image_array_list = []\n",
    "    filename = os.listdir(path_image)[0]\n",
    "    image = Image.open(path_image + \"/\" + filename)\n",
    "    width = image.width\n",
    "    tg_size = (RESIZE_WIDTH, RESIZE_HEIGHT)\n",
    "    for filename in os.listdir(path_image):\n",
    "        no_image += 1\n",
    "        image = Image.open(path_image + \"/\" + filename)\n",
    "        image = image.convert(\"RGB\")\n",
    "        if width != RESIZE_WIDTH:\n",
    "            image = image.resize(tg_size, PIL.Image.ANTIALIAS)    \n",
    "        image_array = np.asarray(image, dtype=np.uint8)\n",
    "        image_array_list.append(image_array)\n",
    "            \n",
    "#        if no_image == 20:  #break for debug mode\n",
    "#            break\n",
    "            \n",
    "    return no_image, image_array_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orgl_no_image, orgl_image_array_list = data_transform2(path_train_image)\n",
    "print(\"orgl_no_image = \", orgl_no_image)\n",
    "print(\"orgl data have been prepared successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_no_image, val_image_array_list = data_transform2(path_val_image)\n",
    "print(\"val_no_image = \", val_no_image)\n",
    "print(\"val data have been prepared successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"display processed original image for checking\")\n",
    "\n",
    "from IPython.display import display_png\n",
    "\n",
    "no = 0\n",
    "for i in range(2):\n",
    "    print(\"processed no = \", no)\n",
    "    orgl_image = Image.fromarray(np.uint8(orgl_image_array_list[i]), mode=\"RGB\")\n",
    "    display_png(orgl_image)\n",
    "    no += 1\n",
    "    \n",
    "print(\"final processed no = \", no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"display processed corrupted image for checking\")\n",
    "\n",
    "from IPython.display import display_png\n",
    "\n",
    "no = 0\n",
    "for i in range(2):\n",
    "    print(\"processed no = \", no)\n",
    "    crpt_image = Image.fromarray(np.uint8(crpt_image_array_list[i]), mode=\"RGB\")\n",
    "    display_png(crpt_image)\n",
    "    no += 1\n",
    "    \n",
    "print(\"final processed no = \", no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"display processed val data for checking\")\n",
    "\n",
    "from IPython.display import display_png\n",
    "\n",
    "no = 0\n",
    "for i in range(2):\n",
    "    print(\"processed no = \", no)\n",
    "    val_image = Image.fromarray(np.uint8(val_image_array_list[i]), mode=\"RGB\")\n",
    "    display_png(val_image)\n",
    "    no += 1\n",
    "    \n",
    "print(\"final processed no = \", no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orgl_data = np.array(orgl_image_array_list, dtype=np.float32)\n",
    "orgl_data = orgl_data / np.float32(255.0)\n",
    "orgl_data = orgl_data.reshape((-1, RESIZE_HEIGHT, RESIZE_WIDTH, 3))\n",
    "\n",
    "print(\"orgl_data.shape = \", orgl_data.shape)\n",
    "print(\"orgl_data have been transformed successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crpt_data = np.array(crpt_image_array_list, dtype=np.float32)\n",
    "crpt_data = crpt_data / np.float32(255.0)\n",
    "crpt_data = crpt_data.reshape((-1, RESIZE_HEIGHT, RESIZE_WIDTH, 3))\n",
    "\n",
    "print(\"crpt_data.shape = \", crpt_data.shape)\n",
    "print(\"crpt_data have been transformed successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_input_data = np.array(val_image_array_list, dtype=np.float32)\n",
    "val_input_data = val_input_data / np.float32(255.0)\n",
    "val_input_data = val_input_data.reshape((-1, RESIZE_HEIGHT, RESIZE_WIDTH, 3))\n",
    "\n",
    "print(\"val_input_data.shape = \", val_input_data.shape)\n",
    "print(\"val_input_data have been transformed successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mtanh(x):\n",
    "    return 0.5*tf.keras.activations.tanh(x) + 0.5\n",
    "\n",
    "input = Input(shape=(RESIZE_HEIGHT, RESIZE_WIDTH, 3))\n",
    "\n",
    "# Encoder\n",
    "# Filter 1\n",
    "e = Conv2D(FILT_NO1, FILT_SIZE, 1, activation='relu', padding='same', kernel_initializer=KNL_INITLZ,\n",
    "        kernel_regularizer=regularizers.l2(L2_VALUE1))(input)\n",
    "e = BatchNormalization()(e)\n",
    "    \n",
    "# Filter 2\n",
    "e = Conv2D(FILT_NO2, (3, 3), 1, activation='relu', padding='same', kernel_initializer=KNL_INITLZ,\n",
    "        kernel_regularizer=regularizers.l2(L2_VALUE2))(e)\n",
    "e = BatchNormalization()(e)\n",
    "\n",
    "# Filter 3\n",
    "e = Conv2D(FILT_NO3, (3, 3), 1, activation='relu', padding='same', kernel_initializer=KNL_INITLZ,\n",
    "        kernel_regularizer=regularizers.l2(L2_VALUE3))(e)\n",
    "e = BatchNormalization()(e)\n",
    "\n",
    "# Filter 4, output is bottleneck\n",
    "e = Conv2D(FILT_NO4, (3, 3), 1, activation='relu', padding='same', kernel_initializer=KNL_INITLZ,\n",
    "        kernel_regularizer=regularizers.l2(L2_VALUE4))(e)\n",
    "bottleneck = BatchNormalization()(e)\n",
    "\n",
    "# Decoder\n",
    "# Filter 5\n",
    "d = Conv2D(FILT_NO3, (3, 3), 1, activation='relu', padding='same', kernel_initializer=KNL_INITLZ,\n",
    "        kernel_regularizer=regularizers.l2(L2_VALUE4))(bottleneck)\n",
    "d = BatchNormalization()(d)\n",
    "\n",
    "# Filter 6\n",
    "d = Conv2D(FILT_NO2, (3, 3), 1, activation='relu', padding='same', kernel_initializer=KNL_INITLZ,\n",
    "        kernel_regularizer=regularizers.l2(L2_VALUE3))(d)\n",
    "d = BatchNormalization()(d)\n",
    "\n",
    "# Filter 7\n",
    "d = Conv2D(FILT_NO1, (3, 3), 1, activation='relu', padding='same', kernel_initializer=KNL_INITLZ,\n",
    "        kernel_regularizer=regularizers.l2(L2_VALUE2))(d)\n",
    "d = BatchNormalization()(d)\n",
    "\n",
    "# Filter 8\n",
    "decoded = Conv2D(3, (3, 3), 1, activation=mtanh, padding='same', kernel_initializer=KNL_INITLZ,\n",
    "        kernel_regularizer=regularizers.l2(L2_VALUE1))(d)\n",
    "\n",
    "model = Model(inputs=[input], outputs=[decoded])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = SGD(lr=LEARN_RATE, momentum=MOMENTUM, nesterov=True)\n",
    "#adam = Adam(lr=LEARN_RATE, beta_1=BETA_1)\n",
    "\n",
    "model.compile(\n",
    "#    optimizer = adam,\n",
    "    optimizer = sgd,\n",
    "    loss='binary_crossentropy'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tsb=TensorBoard(log_dir='.logs')\n",
    "modelcp = ModelCheckpoint(filepath = checkpoint_path,\n",
    "                                  monitor='val_loss',\n",
    "                                  verbose=1,\n",
    "                                  save_best_only=True,\n",
    "                                  save_weights_only=True,\n",
    "                                  mode='min',\n",
    "                                  period=1)\n",
    "\n",
    "history1 = model.fit(\n",
    "    crpt_data,\n",
    "    orgl_data, \n",
    "    initial_epoch = 0,\n",
    "    epochs = EPOCHS1,  \n",
    "    batch_size = BATCH_SIZE,\n",
    "    shuffle = True,     \n",
    "    callbacks = [tsb, modelcp],\n",
    "    validation_data=(val_input_data, val_input_data)\n",
    "    )\n",
    "\n",
    "np.save(path_History + \"/\" + \"history1.npy\", history1.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history2 = model.fit(\n",
    "    crpt_data, \n",
    "    orgl_data, \n",
    "    initial_epoch = EPOCHS1,\n",
    "    epochs = EPOCHS1+EPOCHS2,  \n",
    "    batch_size = BATCH_SIZE, \n",
    "    shuffle = True,  \n",
    "    callbacks = [tsb, modelcp],\n",
    "    validation_data=(val_input_data, val_input_data)\n",
    "    )\n",
    "\n",
    "np.save(path_History + \"/\" + \"history2.npy\", history2.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history3 = model.fit(\n",
    "    crpt_data, \n",
    "    orgl_data, \n",
    "    initial_epoch = EPOCHS1+EPOCHS2,\n",
    "    epochs = EPOCHS1+2*EPOCHS2,  \n",
    "    batch_size = BATCH_SIZE, \n",
    "    shuffle = True,      \n",
    "    callbacks = [tsb, modelcp],\n",
    "    validation_data=(val_input_data, val_input_data)\n",
    "    )\n",
    "\n",
    "np.save(path_History + \"/\" + \"history3.npy\", history3.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history4 = model.fit(\n",
    "    crpt_data, \n",
    "    orgl_data, \n",
    "    initial_epoch = EPOCHS1+2*EPOCHS2,\n",
    "    epochs = EPOCHS1+3*EPOCHS2,   \n",
    "    batch_size = BATCH_SIZE, \n",
    "    shuffle = True,       \n",
    "    callbacks = [tsb, modelcp],\n",
    "    validation_data=(val_input_data, val_input_data)\n",
    "    )\n",
    "\n",
    "np.save(path_History + \"/\" + \"history4.npy\", history4.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history5 = model.fit(\n",
    "    crpt_data, \n",
    "    orgl_data, \n",
    "    initial_epoch = EPOCHS1+3*EPOCHS2,\n",
    "    epochs = EPOCHS1+4*EPOCHS2,   \n",
    "    batch_size = BATCH_SIZE, \n",
    "    shuffle = True,     \n",
    "    callbacks = [tsb, modelcp],\n",
    "    validation_data=(val_input_data, val_input_data)\n",
    "    )\n",
    "\n",
    "np.save(path_History + \"/\" + \"history5.npy\", history5.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history6 = model.fit(\n",
    "    crpt_data, \n",
    "    orgl_data, \n",
    "    initial_epoch = EPOCHS1+4*EPOCHS2,\n",
    "    epochs = EPOCHS1+5*EPOCHS2,   \n",
    "    batch_size = BATCH_SIZE, \n",
    "    shuffle = True,      \n",
    "    callbacks = [tsb, modelcp],\n",
    "    validation_data=(val_input_data, val_input_data)\n",
    "    )\n",
    "\n",
    "np.save(path_History + \"/\" + \"history6.npy\", history6.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(checkpoint_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Model(inputs=[input], outputs=[bottleneck])\n",
    "encoder.save_weights(encoder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train image predict and display\n",
    "from IPython.display import display_png\n",
    "\n",
    "predict_no = 10\n",
    "i = 0\n",
    "for i in range(predict_no):    \n",
    "    crpt_image = crpt_data[i]\n",
    "    input_bt = np.expand_dims(crpt_image, axis=0)\n",
    "    \n",
    "    predict_bt = model.predict_on_batch(input_bt)\n",
    "\n",
    "    predict = np.squeeze(predict_bt, 0)\n",
    "    train_predict_image1 = np.uint8(predict*255.0 + 0.5)\n",
    "    train_predict_image = Image.fromarray(train_predict_image1, mode=\"RGB\")\n",
    "    crpt_image_RGB = Image.fromarray(np.uint8(crpt_image_array_list[i]), mode=\"RGB\")\n",
    "    display_png(train_predict_image)\n",
    "    display_png(crpt_image_RGB)\n",
    "    print(\"i = \", i)\n",
    "    \n",
    "print(\"processing has finished successfully, i = \", i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val image predict and display\n",
    "from IPython.display import display_png\n",
    "\n",
    "predict_no = 10\n",
    "i = 0\n",
    "for i in range(predict_no):    \n",
    "    val_image = val_input_data[i]\n",
    "    input_bt = np.expand_dims(val_image, axis=0)\n",
    "    \n",
    "    predict_bt = model.predict_on_batch(input_bt)\n",
    "\n",
    "    predict = np.squeeze(predict_bt, 0)\n",
    "    val_predict_image1 = np.uint8(predict*255.0 + 0.5)    \n",
    "    val_predict_image = Image.fromarray(val_predict_image1, mode=\"RGB\")\n",
    "    val_image_RGB = Image.fromarray(np.uint8(val_image_array_list[i]), mode=\"RGB\")\n",
    "    display_png(val_predict_image)\n",
    "    display_png(val_image_RGB)\n",
    "    print(\"i = \", i)\n",
    "\n",
    "print(\"processing has finished successfully, i = \", i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display_png\n",
    "path_train_predict_folder = \"C:/Users/test/Documents/Cityscapes/Predict/Train_Predict\" #path to Predict folder\n",
    "predict_no = 10\n",
    "i = 0\n",
    "for i in range(predict_no):    \n",
    "    crpt_image = crpt_data[i]\n",
    "    input_bt = np.expand_dims(crpt_image, axis=0)\n",
    "    \n",
    "    predict_bt = model.predict_on_batch(input_bt)\n",
    "\n",
    "    predict = np.squeeze(predict_bt, 0)\n",
    "    train_predict_image1 = np.uint8(predict*255.0 + 0.5)\n",
    "    train_predict_image = Image.fromarray(train_predict_image1, mode=\"RGB\")\n",
    "    crpt_image_RGB = Image.fromarray(np.uint8(crpt_image_array_list[i]), mode=\"RGB\")\n",
    "    display_png(train_predict_image)\n",
    "    display_png(crpt_image_RGB)\n",
    "    \n",
    "    filename = \"orglmage\" + str(i) + \".png\"\n",
    "    orgl_image = Image.fromarray(np.uint8(orgl_image_array_list[i]), mode=\"RGB\")\n",
    "    orgl_image.save(path_train_predict_folder + \"/\" + filename)\n",
    "\n",
    "    filename = \"crptimage\" + str(i) + \".png\"\n",
    "    crpt_image = Image.fromarray(np.uint8(crpt_image_array_list[i]), mode=\"RGB\")\n",
    "    crpt_image.save(path_train_predict_folder + \"/\" + filename)\n",
    "\n",
    "    filename = \"prdtimage\" + str(i) + \".png\"\n",
    "    train_predict_image.save(path_train_predict_folder + \"/\" + filename)\n",
    "        \n",
    "    print(\"i = \", i)\n",
    "    \n",
    "print(\"processing has finished successfully, i = \", i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val image predict and display\n",
    "from IPython.display import display_png\n",
    "path_val_predict_folder = \"C:/Users/test/Documents/Cityscapes/Predict/Val_Predict\" #path to Predict folder\n",
    "\n",
    "predict_no = 10\n",
    "i = 0\n",
    "for i in range(predict_no):    \n",
    "    val_image = val_input_data[i]\n",
    "    input_bt = np.expand_dims(val_image, axis=0)\n",
    "    \n",
    "    predict_bt = model.predict_on_batch(input_bt)\n",
    "\n",
    "    predict = np.squeeze(predict_bt, 0)\n",
    "    val_predict_image1 = np.uint8(predict*255.0 + 0.5)    \n",
    "    val_predict_image = Image.fromarray(val_predict_image1, mode=\"RGB\")\n",
    "    val_image_RGB = Image.fromarray(np.uint8(val_image_array_list[i]), mode=\"RGB\")\n",
    "    display_png(val_predict_image)\n",
    "    display_png(val_image_RGB)\n",
    "    \n",
    "    filename = \"valmage\" + str(i) + \".png\"\n",
    "    val_image = Image.fromarray(np.uint8(val_image_array_list[i]), mode=\"RGB\")\n",
    "    val_image.save(path_val_predict_folder + \"/\" + filename)\n",
    "    \n",
    "    filename = \"valprdtimage\" + str(i) + \".png\"\n",
    "    val_predict_image.save(path_val_predict_folder + \"/\" + filename)    \n",
    "    \n",
    "    print(\"i = \", i)\n",
    "\n",
    "print(\"processing has finished successfully, i = \", i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = model.evaluate(crpt_data, orgl_data)\n",
    "print(\"Restored model, train_loss: {:.4f}\".format(train_loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss = model.evaluate(val_input_data, val_input_data)\n",
    "print(\"Restored model, val_loss: {:.4f}\".format(val_loss))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
